{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leofl\\AppData\\Local\\Temp\\ipykernel_25504\\2470113652.py:7: DeprecationWarning: \n",
      "The `fooof` package is being deprecated and replaced by the `specparam` (spectral parameterization) package.\n",
      "This version of `fooof` (1.1) is fully functional, but will not be further updated.\n",
      "New projects are recommended to update to using `specparam` (see Changelog for details).\n",
      "  from fooof import FOOOF\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "from itertools import chain\n",
    "from scipy.fft import fft, fftfreq\n",
    "from fooof import FOOOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eeg_files(folder_path):\n",
    "    y_frequencies_dict = {}\n",
    "    \n",
    "    # Loop over all .set files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.set'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            raw_eeg = mne.io.read_raw_eeglab(file_path, preload=True)\n",
    "            \n",
    "            # Preprocess the raw EEG data\n",
    "            raw_eeg = preprocess_raw_eeg(raw_eeg)\n",
    "            \n",
    "            # Extract and modify events\n",
    "            events, event_id = extract_and_modify_events(raw_eeg)\n",
    "            \n",
    "            # Create epochs\n",
    "            epochs = create_epochs(raw_eeg, events, event_id)\n",
    "\n",
    "            conditions = ['frequent_rare', 'rare_frequent', 'frequent_frequent']\n",
    "            \n",
    "            y_frequencies_dict[filename.split('.')[0]] = {}\n",
    "            for condition in conditions: \n",
    "\n",
    "                # Separate epochs into pre and post-stimulus windows\n",
    "                epochs_pre, epochs_post = separate_epochs(epochs[condition])\n",
    "\n",
    "                assert len(epochs_pre) == len(epochs_post)\n",
    "                \n",
    "                # Perform FFT on the Pz channel data\n",
    "                yf_avg_pre, yf_avg_post = perform_fft_on_epochs(epochs_pre, epochs_post)\n",
    "                \n",
    "                xf = get_xf(epochs_pre)\n",
    "\n",
    "                assert yf_avg_pre.shape == xf.shape \n",
    "\n",
    "                #Compute ERP for condition\n",
    "                erp = compute_erp(epochs_post[condition])\n",
    "\n",
    "                #Compute FFT for ERP\n",
    "                fft_erp = perform_fft_on_erp(erp)\n",
    "                \n",
    "                xf_erp = get_xf(erp)\n",
    "                \n",
    "                assert fft_erp.shape == xf_erp.shape\n",
    "\n",
    "                #subtracting the erp  from the post event data for each candidate\n",
    "                post_minus_erp = yf_avg_post - fft_erp\n",
    "\n",
    "                power_spec_windows = [\n",
    "                    (\"yf_avg_pre\", yf_avg_pre),\n",
    "                    (\"yf_avg_post\", yf_avg_post),\n",
    "                    (\"post_minus_erp\", post_minus_erp)\n",
    "                ]\n",
    "                results = {}\n",
    "                for name, power_spec in power_spec_windows:\n",
    "                \n",
    "                    fg = FOOOF(\n",
    "                        #had to modify peak width limits because using different time series data then gyurkovics\n",
    "                            peak_width_limits=[2.5, 8],\n",
    "                            max_n_peaks= 1,\n",
    "                            min_peak_height=0.3,\n",
    "                            peak_threshold=2.0,\n",
    "                            aperiodic_mode='fixed'\n",
    "                        )\n",
    "\n",
    "                    #the parameters for fit are frequency data of the power spectra (xf) and frequency (yf_avg) \n",
    "                    #frequency range from gyurkovics defined a as >2 hz but <25hz\n",
    "                    fg.fit(xf, power_spec, freq_range= (2,25))\n",
    "\n",
    "                    aps = fg.get_params('aperiodic_params')\n",
    "                    rsq = fg.get_params('r_squared')\n",
    "\n",
    "                    results[name] = {\n",
    "                            name : power_spec,\n",
    "                            'aps': aps,\n",
    "                            'rsq': rsq,\n",
    "                        }\n",
    "                \n",
    "                results.update({\n",
    "                        'fft_erp': fft_erp,\n",
    "                        'xf': xf,\n",
    "                        'xf_erp' : xf_erp \n",
    "                })\n",
    "\n",
    "                # results = results + [fft_erp, xf, xf_erp]\n",
    "                # Update the dictionary with the results\n",
    "                y_frequencies_dict[filename.split('.')[0]][condition] = results\n",
    "    \n",
    "    return y_frequencies_dict\n",
    "\n",
    "def preprocess_raw_eeg(raw_eeg):\n",
    "    \"\"\"\n",
    "    Preprocess the raw EEG data by setting the montage, renaming channels, and setting channel types.\n",
    "    \"\"\"\n",
    "    # Set standard 10-20 montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw_eeg.rename_channels({\"FP1\": 'Fp1', 'FP2': 'Fp2'})\n",
    "    raw_eeg.set_channel_types({\n",
    "        'HEOG_left': 'eog', 'HEOG_right': 'eog',\n",
    "        'VEOG_lower': 'eog', '(uncorr) HEOG': 'eog',\n",
    "        '(uncorr) VEOG': 'eog'\n",
    "    })\n",
    "    raw_eeg.set_montage(montage)\n",
    "    return raw_eeg\n",
    "\n",
    "def extract_and_modify_events(raw_eeg):\n",
    "    \"\"\"\n",
    "    Extract events from annotations and modify event IDs according to specific conditions.\n",
    "    \"\"\"\n",
    "    events, _ = mne.events_from_annotations(raw_eeg)\n",
    "    \n",
    "    # Remove events with IDs 6 and 7\n",
    "    events = events[~np.isin(events[:, 2], [6, 7])]\n",
    "    \n",
    "    # Define target and non-target event IDs\n",
    "    target_ids = [1, 9, 15, 21, 27]\n",
    "    nontarget_ids = [2, 3, 4, 5, 8, 10, 11, 12, 13, 14,\n",
    "                     16, 17, 18, 19, 20, 22, 23, 24, 25, 26]\n",
    "    \n",
    "    # Modify event IDs based on conditions\n",
    "    for i in range(len(events)):\n",
    "        current_id = events[i, 2]\n",
    "        if current_id in target_ids:\n",
    "            events[i, 2] = 100  # 'frequent_rare'\n",
    "        elif (i > 0 and current_id in nontarget_ids and\n",
    "              events[i - 1, 2] == 100):\n",
    "            events[i, 2] = 200  # 'rare_frequent'\n",
    "        elif (i > 0 and current_id in nontarget_ids and\n",
    "              events[i - 1, 2] in [200, 300]):\n",
    "            events[i, 2] = 300  # 'frequent_frequent'\n",
    "    \n",
    "    # Define new event IDs\n",
    "    event_id = {\n",
    "        \"frequent_rare\": 100,\n",
    "        \"rare_frequent\": 200,\n",
    "        \"frequent_frequent\": 300\n",
    "    }\n",
    "    return events, event_id\n",
    "\n",
    "def create_epochs(raw_eeg, events, event_id):\n",
    "    \"\"\"\n",
    "    Create epochs from the raw EEG data using the modified events.\n",
    "    \"\"\"\n",
    "    epochs = mne.Epochs(\n",
    "        raw_eeg, events=events, event_id=event_id,\n",
    "        tmin=-0.6, tmax=0.6, picks=['Pz'],\n",
    "        baseline=None, preload=True\n",
    "    )\n",
    "    return epochs\n",
    "\n",
    "def separate_epochs(epochs):\n",
    "    \"\"\"\n",
    "    Separate epochs into pre-stimulus and post-stimulus windows.\n",
    "    \"\"\"\n",
    "    epochs_pre = epochs.copy().crop(tmin=-0.6, tmax=0)\n",
    "    epochs_post = epochs.copy().crop(tmin=0, tmax=0.6)\n",
    "    return epochs_pre, epochs_post\n",
    "\n",
    "def perform_fft_on_epochs(epochs_pre, epochs_post):\n",
    "    \"\"\"\n",
    "    Perform FFT on the Pz channel data of pre and post-stimulus epochs.\n",
    "    \"\"\"\n",
    "    # .get_data() Shape: (n_epochs x n_channels x n_samples)\n",
    "    pre_data = epochs_pre.copy().pick(['Pz']).get_data()  # Select PZ Shape: n_epochs x 1 x n_samples\n",
    "    post_data = epochs_post.copy().pick(['Pz']).get_data()\n",
    "\n",
    "    # Remove channel dimension \n",
    "    pre_data = pre_data[:, 0, :]  # now n_epochs x n_samples\n",
    "    post_data = post_data[:, 0, :]\n",
    "\n",
    "    # Compute FFT for each trial\n",
    "    pre_spectra = np.abs(fft(pre_data, axis=1))  # axis 1 applies FFT along n_samples\n",
    "    post_spectra = np.abs(fft(post_data, axis=1)) # resulting arraray now for each epoch\n",
    "\n",
    "    # Avg after FFT in freq domain\n",
    "    yf_avg_pre = pre_spectra.mean(axis=0)  # now averaging across trials (epochs)\n",
    "    yf_avg_post = post_spectra.mean(axis=0) # so will give 1 row of sample data\n",
    "    \n",
    "    return yf_avg_pre, yf_avg_post\n",
    "\n",
    "def compute_erp(epochs_post): \n",
    "    erp = epochs_post.average() \n",
    "    return erp\n",
    "\n",
    "def perform_fft_on_erp(erp):\n",
    "    data = erp.pick(['Pz']).get_data()\n",
    "    print(data.shape)\n",
    "    erp_mean = data.mean(axis=0)\n",
    "    print(erp_mean.shape)\n",
    "    erp_avg =  np.abs(fft(erp_mean))\n",
    "    return erp_avg\n",
    "\n",
    "\n",
    "def get_xf(epoch_window):\n",
    "\n",
    "    # Getting the sampling frequency\n",
    "    sample_rate = epoch_window.info['sfreq']\n",
    "\n",
    "    # Acessing the num of epochs, channels, and time points\n",
    "    data = epoch_window.get_data()\n",
    "\n",
    "    #N is required for xf calculations\n",
    "    N = data.shape[-1]\n",
    "\n",
    "    xf = fftfreq(N, 1/sample_rate)\n",
    "    return xf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    folder_path = \"C:/Users/leofl/OneDrive/Desktop/ERP Data/Project Cygnus/\"\n",
    "    y_frequencies_dict = process_eeg_files(folder_path)\n",
    "    # Now y_frequencies_dict contains the FFT results for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "155\n",
      "155\n",
      "155\n",
      "155\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['post_minus_erp']))\n",
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['fft_erp']))\n",
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['fft_erp']))\n",
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['fft_erp']))\n",
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['fft_erp']))\n",
    "print(len(y_frequencies_dict['p3_1']['frequent_frequent']['fft_erp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_frequencies_dict['p3_1']['frequent_frequent']['post_minus_erp']['aps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in y_frequencies_dict:\n",
    "    for condition in y_frequencies_dict[participant]:\n",
    "\n",
    "        # Access yf_avg_pre (Index 0)\n",
    "        yf_avg_pre = y_frequencies_dict[participant][condition]['yf_avg_pre']['yf_avg_pre']\n",
    "\n",
    "        # Access yf_avg_post (Index 1)\n",
    "        yf_avg_post = y_frequencies_dict[participant][condition]['yf_avg_post']['yf_avg_post']\n",
    "\n",
    "        # Acess the frequencies (Index 3)\n",
    "        xf = y_frequencies_dict[participant][condition]['xf']\n",
    "\n",
    "        # Acess number of samples\n",
    "        N = len(xf)\n",
    "\n",
    "        # Filtering frequencies above 25 hz\n",
    "        mask = xf[:N // 2] <= 25\n",
    "\n",
    "        # convert yf_avg_pre and post from volts to microvolts\n",
    "        scaling_factor = 1e6  # From volts to microvolts\n",
    "        yf_avg_pre_scaled = yf_avg_pre * scaling_factor**2  # Convert amplitude^2\n",
    "        yf_avg_post_scaled = yf_avg_post * scaling_factor**2\n",
    "\n",
    "        plt.plot(xf[:N // 2][mask], yf_avg_pre_scaled[:N // 2][mask], color = 'blue', label = 'pre-event')\n",
    "        plt.plot(xf[:N // 2][mask], yf_avg_post_scaled[:N // 2][mask],  color = 'red', label = 'post-event')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'Power ($\\mu V^2/Hz$)')\n",
    "        plt.title(f'{participant}'+ ' ' + f'{condition} Power Spectrum')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leofl\\anaconda3\\envs\\preprocesseeg\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\leofl\\anaconda3\\envs\\preprocesseeg\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m yf_avg_pre_scaled \u001b[38;5;241m=\u001b[39m yf_avg_pre_mean \u001b[38;5;241m*\u001b[39m scaling_factor\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Convert amplitude^2\u001b[39;00m\n\u001b[0;32m     31\u001b[0m yf_avg_post_scaled \u001b[38;5;241m=\u001b[39m yf_avg_post_mean \u001b[38;5;241m*\u001b[39m scaling_factor\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 33\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(xf[:N \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m][mask], \u001b[43myf_avg_pre_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m[mask], color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre-event\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(xf[:N \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m][mask], yf_avg_post_scaled[:N \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m][mask],  color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost-event\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency (Hz)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "conditions = ['frequent_rare', 'rare_frequent', 'frequent_frequent']\n",
    "\n",
    "\n",
    "for condition in conditions:  \n",
    "    yf_avg_pre_list = []\n",
    "    yf_avg_post_list = []\n",
    "    for participant in y_frequencies_dict:\n",
    "        # Access yf_avg_pre (Index 0)\n",
    "        yf_avg_pre = y_frequencies_dict[participant][condition]['yf_avg_pre']['yf_avg_pre']\n",
    "\n",
    "        # Access yf_avg_post (Index 1)\n",
    "        yf_avg_post = y_frequencies_dict[participant][condition]['yf_avg_post']['yf_avg_post']\n",
    "\n",
    "    # Acess the frequencies (Index 3) (doesnt matter which one we use so just used first index)\n",
    "    xf = y_frequencies_dict['p3_1']['frequent_rare']['xf']\n",
    "\n",
    "    # Acess number of samples\n",
    "    N = len(xf)\n",
    "\n",
    "    # Filtering frequencies above 25 hz\n",
    "    mask = (xf[:N // 2] <= 25) & (xf[:N // 2] > 2)\n",
    "\n",
    "    # Take the average across particpants (axis 0 since participants in rows)\n",
    "    yf_avg_pre_mean =  np.mean(yf_avg_pre_list, axis = 0)\n",
    "    yf_avg_post_mean =  np.mean(yf_avg_post_list, axis = 0)\n",
    "\n",
    "\n",
    "    # convert yf_avg_pre and post from volts to microvolts\n",
    "    scaling_factor = 1e6  # From volts to microvolts\n",
    "    yf_avg_pre_scaled = yf_avg_pre_mean * scaling_factor**2  # Convert amplitude^2\n",
    "    yf_avg_post_scaled = yf_avg_post_mean * scaling_factor**2\n",
    "\n",
    "    plt.plot(xf[:N // 2][mask], yf_avg_pre_scaled[:N // 2][mask], color = 'blue', label = 'pre-event')\n",
    "    plt.plot(xf[:N // 2][mask], yf_avg_post_scaled[:N // 2][mask],  color = 'red', label = 'post-event')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel(r'Power ($\\mu V^2/Hz$)')\n",
    "    plt.title(f'{condition} Power Spectrum')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FOOOFGroup(\n",
    "    peak_width_limits=[2, 8],\n",
    "    max_n_peaks= 10,\n",
    "    min_peak_height=0.3,\n",
    "    peak_threshold=2.0,\n",
    "    aperiodic_mode='fixed'\n",
    ")\n",
    "\n",
    "freq = y_frequencies_dict['p3_1']['frequent_rare'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m freq \u001b[38;5;241m=\u001b[39m y_frequencies_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp3_1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequent_rare\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfreq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocesseeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
